= Apache Flink for Java Developers Workshop
Viktor Gamov <viktor@confluent.io>
v1.0, 2025-02-17
:toc:

== üìö Workshop Description & Learning Objectives

You were tasked with building a real-time platform, but traditional tools couldn‚Äôt handle the massive data streams, leading to lagging performance and frustrated users. 
Deadlines were looming, and the team needed a breakthrough.

And when you learned about Apache Flink.

We‚Äôll explore how the DataStream API allowed efficient real-time data processing and how the Table API and SQL features simplified complex queries with familiar syntax. 
Testing became more straightforward, and managing the application state was no longer a headache.

You‚Äôll learn:

‚Ä¢ Harnessing the DataStream API: Process unbounded data streams efficiently to make your applications more responsive.
‚Ä¢ Unlocking Table API and SQL: Use SQL queries within Flink to simplify data processing tasks without learning new languages.
‚Ä¢ Effective Testing Strategies: Implement best practices for testing Flink applications to ensure your code is robust and reliable.
‚Ä¢ Stateful Stream Processing: Manage application state effectively for complex event processing and real-time analytics.

By the end of this talk, you‚Äôll be equipped to tackle real-time data challenges. 
Whether you are building analytics dashboards, event-driven systems, or handling data streams, Apache Flink can be the game-changer you‚Äôve been searching for.

== üíª Technical Prerequisites
1. *Basic Programming Knowledge* ‚Äì Familiarity with **Java** or **Scala** (ugh) (Flink supports both but not for long).
2. *Understanding of Stream Processing Concepts* ‚Äì Awareness of real-time data pipelines, event-driven architectures, and streaming frameworks.
3. *SQL Proficiency* ‚Äì Basic understanding of SQL for working with Flink‚Äôs **Table API**.
4. *Linux/macOS Command Line Experience* ‚Äì Ability to execute terminal commands and navigate a Unix-like environment.

== üîß Required Software and Setup

=== 1Ô∏è‚É£ Docker & Docker Compose (Mandatory)
*Why?* Flink and Kafka components will be containerized.
*Download & Install:* https://www.docker.com/get-started[Docker Website]

=== 2Ô∏è‚É£ Confluent Cloud Account (Mandatory)
*Why?* Required for Kafka-based streaming exercises.
*Sign Up & Get API Keys:* https://www.confluent.io/confluent-cloud/[Confluent Cloud]

=== 3Ô∏è‚É£ Java 21 Installed
*Why?* Apache Flink will run on Java 21.
*Download Java 21 (Adoptium Temurin):* https://adoptium.net/[Adoptium Temurin]
*Verify Installation:* Run `java -version` in the terminal.

=== 4Ô∏è‚É£ Git Installed
*Why?* For cloning repositories and working with project files.
*Download Git:* https://git-scm.com/downloads[Git Website]

=== 5Ô∏è‚É£ IDE with Flink Support
*Why?* Recommended for Flink development.
*Download IntelliJ IDEA (Recommended):* https://www.jetbrains.com/idea/download/[IntelliJ IDEA]
*Download VS Code (Alternative):* https://code.visualstudio.com/download[VS Code]

=== 6Ô∏è‚É£ Gradle Installed via Wrapper (No Need for Local Installation)
*Why?* The workshop will use the **Gradle Wrapper**, eliminating the need for manual installation.
*Gradle Docs:* https://docs.gradle.org/current/userguide/gradle_wrapper.html[Gradle Wrapper Documentation]

== üåê Network & System Requirements

1. *Stable Internet Connection* ‚Äì Required for downloading dependencies and connecting to Confluent Cloud.
2. *8GB+ RAM Recommended* ‚Äì Running Flink, Kafka, and other services may require significant memory.
3. *Sufficient Disk Space (At Least 10GB Free)* ‚Äì For Docker images, logs, and data processing.

== ‚öôÔ∏è Optional but Recommended

=== 1Ô∏è‚É£ Terraform Installed
*Why?* Useful for automated infrastructure setup.
*Download Terraform:* https://developer.hashicorp.com/terraform/downloads[Terraform Website]

=== 2Ô∏è‚É£ Basic Understanding of Terraform and IaC (Infrastructure as Code)
*Why?* If Terraform scripts are used, a fundamental knowledge of how it works would be beneficial.
*Terraform Getting Started Guide:* https://developer.hashicorp.com/terraform/tutorials[Terraform Tutorials]

=== 3Ô∏è‚É£ Confluent CLI
*Why?* The workshop will use the commands in the Confluent CLI to get useful information about new Confluent infrastructure.
*Download and Install:* https://docs.confluent.io/confluent-cli/current/install.html[Confluent CLI Installation Instructions]

=== 4Ô∏è‚É£ jq
*Why?* The workshop will use jq to build configuration files used to demonstrate the Confluent Flink Table API.
*Download and Install:* https://jqlang.org/download/[jq Download Instructions]

== üìå Pre-Workshop Setup Tasks

1. *Sign up for Confluent Cloud & Configure API Keys* ‚Äì Ensure access credentials are available before the workshop.
2. *Clone the Workshop Repository* ‚Äì The repo will include pre-built examples and configuration files (GitHub link will be shared before the workshop).
3. *Set Up Environment Variables* ‚Äì Configure `JAVA_HOME` and authentication variables for Confluent Cloud.
4. *Run a Simple Docker-Based Flink Job* ‚Äì Validate that the environment is correctly configured.